{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.147 ðŸš€ Python-3.11.4 torch-2.0.1+cpu CPU (13th Gen Intel Core(TM) i7-13700KF)\n",
      "Setup complete âœ… (24 CPUs, 31.2 GB RAM, 291.8/937.3 GB disk)\n"
     ]
    }
   ],
   "source": [
    "import ultralytics\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "# from PIL import Image\n",
    "# import requests\n",
    "# from io import BytesIO\n",
    "import cv2\n",
    "ultralytics.checks()\n",
    "import supervision as sv\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\n",
    "    '/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/notebooks/yolov8n.pt', \n",
    "    task='detect') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(img_path):\n",
    "    \"\"\"\n",
    "    Predict objects in the image using the YOLO model.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path: Path to the input image.\n",
    "\n",
    "    Returns:\n",
    "    - detections: Detected objects in the image.\n",
    "    \"\"\"\n",
    "    # predictions = model.predict(img, show=True, imgsz=(1253,705))\n",
    "    # if format == 'RGB':\n",
    "    #     # Skip the BGR to RGB conversion\n",
    "    #     pass\n",
    "    # else:\n",
    "    #     # Convert from BGR to RGB\n",
    "    #     img = img[..., ::-1]\n",
    "    \n",
    "    results = model.predict(img_path)\n",
    "    # detections = sv.Detections.from_yolov8(predictions[0])\n",
    "    detections = sv.Detections(\n",
    "        xyxy=results[0].boxes.xyxy.cpu().numpy(),\n",
    "        confidence=results[0].boxes.conf.cpu().numpy(),\n",
    "        class_id=results[0].boxes.cls.cpu().numpy().astype(int),\n",
    "    )\n",
    "\n",
    "    return results, detections\n",
    "\n",
    "def box_annotate(img, detections):\n",
    "    \"\"\"\n",
    "    Annotate the image with bounding boxes and labels.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path: Path to the input image.\n",
    "    - detections: Detected objects in the image.\n",
    "\n",
    "    Returns:\n",
    "    - annotated_image: Image with annotations.\n",
    "    \"\"\"\n",
    "\n",
    "    # dict maping class_id to class_name\n",
    "    CLASS_NAMES_DICT = model.model.names\n",
    "    # class_ids of interest - car, motorcycle, bus and truck\n",
    "    # CLASS_ID = [2, 3, 5, 7]\n",
    "    CLASS_ID = [2]\n",
    "    \n",
    "    if isinstance(img, str):\n",
    "        # input_data is a path to the image file\n",
    "        img = cv2.imread(img)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image from {img}\")\n",
    "    elif isinstance(img, np.ndarray):\n",
    "        # input_data is a numpy array\n",
    "        img = img\n",
    "        \n",
    "   \n",
    "    box_annotator = sv.BoxAnnotator(thickness=1, text_thickness=1, text_scale=0.5, text_padding= 1)\n",
    "    labels = [\n",
    "        f\"{CLASS_NAMES_DICT[class_id]} {confidence:0.2f}\"\n",
    "        for _, confidence, class_id, tracker_id in detections\n",
    "    ]\n",
    "\n",
    "    annotated_image = box_annotator.annotate(img, detections=detections, labels=labels)\n",
    "    \n",
    "    plt.figure(figsize=(100,100))\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.title(\"annotated\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "def process_and_display_image(img_path, x, y, w, h, display_original=True, display_cropped=True):\n",
    "    \"\"\"\n",
    "    Load an image, crop it, and display the original and cropped images.\n",
    "\n",
    "    Parameters:\n",
    "    - img_path: Path to the input image.\n",
    "    - x, y: Coordinates for the top-left corner of the cropping rectangle.\n",
    "    - w, h: Width and height of the cropping rectangle.\n",
    "    - display_original: Whether to display the original image.\n",
    "    - display_cropped: Whether to display the cropped image.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "   \n",
    "    if isinstance(img_path, str):\n",
    "        # input_data is a path to the image file\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Failed to load image from {img_path}\")\n",
    "    elif isinstance(img_path, np.ndarray):\n",
    "        # input_data is a numpy array\n",
    "        img = img_path\n",
    "        \n",
    "    # Convert to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Crop the image\n",
    "    crop_img = img[y:y+h, x:x+w]\n",
    "    crop_img_rgb = cv2.cvtColor(crop_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "     #display_original:\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title('Original Image')\n",
    "\n",
    "    #display_cropped:\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(crop_img_rgb)\n",
    "    plt.title('Cropped Image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return crop_img_rgb\n",
    "\n",
    "def save_detections_to_file(detections, save_path):\n",
    "    with open(save_path, 'w') as file:\n",
    "        json.dump(detections, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Path to the folder containing images\n",
    "# image_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_selected/\"\n",
    "\n",
    "# image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "# # Path to the folder where evaluated images will be saved\n",
    "# save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/\"\n",
    "\n",
    "# crop_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/crop/\"\n",
    "\n",
    "# detections_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/detections/\"\n",
    "\n",
    "# gt_json_file = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/crop/slakt_gt_coco.json\"\n",
    "\n",
    "# coco_json_path =\"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/crop/slakt_gt_coco.json \"\n",
    "\n",
    "# gt_save_folder  = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/crop/\"\n",
    "\n",
    "# evals_save_folder =  \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/slakt_evaluated/evals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Path to the folder containing images\n",
    "# image_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/\"\n",
    "\n",
    "# image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "# # Path to the folder where evaluated images will be saved\n",
    "# save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/\"\n",
    "\n",
    "# crop_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/crop/\"\n",
    "\n",
    "# detections_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/detections/\"\n",
    "\n",
    "# gt_json_file = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/crop/kris_gt_coco.json\"\n",
    "\n",
    "# coco_json_path =\"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/crop/kris_gt_coco.json \"\n",
    "\n",
    "# gt_save_folder  = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/crop/\"\n",
    "\n",
    "# evals_save_folder =  \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/evals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Path to the folder containing images\n",
    "# image_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_selected/\"\n",
    "\n",
    "# image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "# # Path to the folder where evaluated images will be saved\n",
    "# save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/\"\n",
    "\n",
    "# crop_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/crop/\"\n",
    "\n",
    "# detections_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/detections/\"\n",
    "\n",
    "# gt_json_file = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/crop/varb_gt_coco.json\"\n",
    "\n",
    "# coco_json_path =\"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/crop/varb_gt_coco.json \"\n",
    "\n",
    "# gt_save_folder  = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/crop/\"\n",
    "\n",
    "# evals_save_folder =  \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/varb_evaluated/evals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the folder containing images\n",
    "image_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/\"\n",
    "\n",
    "image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "# Path to the folder where evaluated images will be saved\n",
    "save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/\"\n",
    "\n",
    "# crop_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/crop/\"\n",
    "\n",
    "detections_save_folder = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/detections/\"\n",
    "\n",
    "# gt_json_file = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_evaluated/crop/kris_gt_coco.json\"\n",
    "\n",
    "coco_json_path =\"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/not_crop/kris_orginal_gt_coco.json \"\n",
    "\n",
    "gt_save_folder  = \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/\"\n",
    "\n",
    "evals_save_folder =  \"/home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/evals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_detections_to_file(detections, image_width, image_height, output_file_path):\n",
    "    \"\"\"\n",
    "    Write YOLOv8 detection results to a file in YOLO format.\n",
    "\n",
    "    Parameters:\n",
    "    detections (object): The detection result from YOLOv8.\n",
    "    image_width (int): Width of the image on which detection was performed.\n",
    "    image_height (int): Height of the image on which detection was performed.\n",
    "    output_file_path (str): Path to the output file where results will be written.\n",
    "    \"\"\"\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        for bbox, class_id in zip(detections.xyxy, detections.class_id):\n",
    "            # Extract bounding box coordinates\n",
    "            x_min, y_min, x_max, y_max = bbox\n",
    "\n",
    "            # Convert to YOLO format: [x_center, y_center, width, height], normalized\n",
    "            x_center = ((x_min + x_max) / 2) / image_width\n",
    "            y_center = ((y_min + y_max) / 2) / image_height\n",
    "            width = (x_max - x_min) / image_width\n",
    "            height = (y_max - y_min) / image_height\n",
    "\n",
    "            # Write the formatted string to the file\n",
    "            file.write(f\"{class_id} {x_center} {y_center} {width} {height}\\n\")\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to load image from /home/sf_afn/Insync/sofiaa720@gmail.com/Google Drive/masters_thesis/code_v1/msc_parking/univrses/data/eval_subset_samples/kris_selected/Kris-0510-1914_gt.txt\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.0) /home/conda/feedstock_root/build_artifacts/libopencv_1690022559654/work/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m     img \u001b[38;5;241m=\u001b[39m img_path\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Convert to RGB\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m img_rgb \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(img, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB)\n\u001b[1;32m     22\u001b[0m height, width \u001b[38;5;241m=\u001b[39m img_rgb\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH, W: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheight\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwidth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /home/conda/feedstock_root/build_artifacts/libopencv_1690022559654/work/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ensure the detections save folder exists\n",
    "if not os.path.exists(detections_save_folder):\n",
    "    os.makedirs(detections_save_folder)\n",
    "\n",
    "for image_file in image_files:\n",
    "    \n",
    "    img_path = os.path.join(image_folder, image_file)\n",
    "    \n",
    "    if isinstance(img_path, str):\n",
    "        # input_data is a path to the image file\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            print(f\"Failed to load image from {img_path}\")\n",
    "            pass\n",
    "    elif isinstance(img_path, np.ndarray):\n",
    "        # input_data is a numpy array\n",
    "        img = img_path\n",
    "    \n",
    "    # Convert to RGB\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    height, width = img_rgb.shape[:2]\n",
    "    print(f\"H, W: {height},{width}\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # res_org, detections_org = predictions(image_path)  # Detections on uncropped images\n",
    "    res,detections = predictions(img_rgb)  # Detections on cropped images\n",
    "    \n",
    "    # annotated_org = box_annotate(image_path, detections_org)\n",
    "    annotated = box_annotate(img_rgb, detections)\n",
    "    \n",
    "    # Define the output file path\n",
    "    output_file_path = os.path.join(detections_save_folder, os.path.splitext(image_file)[0] + '_detections.txt')\n",
    "\n",
    "    # Write detections to the file\n",
    "    write_detections_to_file(detections, width, height, output_file_path)\n",
    "    print(f\"Detections for {image_file} written to {output_file_path}\")\n",
    "    \n",
    "    # # Save cropped image detections\n",
    "    # detections_crop_save_path = os.path.join(detections_save_folder, f\"crop_{image_file}.json\")\n",
    "    # save_detections_to_file(detections_crop, detections_crop_save_path)\n",
    "    \n",
    "    # Generate unique save path for each annotated image\n",
    "    save_to_filename = os.path.join(save_folder, image_file)\n",
    "\n",
    "    # Save the annotated image\n",
    "    cv2.imwrite(save_to_filename, annotated)\n",
    "\n",
    "    # print(f\"{image_file} Original: {res_org},{detections_org}\")\n",
    "    # print(f\"{image_file}Croppd: {res_crop}, {detections_crop}\")\n",
    "    # print(f\"{image_file} file saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Ensure the detections save folder exists\n",
    "# if not os.path.exists(detections_save_folder):\n",
    "#     os.makedirs(detections_save_folder)\n",
    "\n",
    "# for image_file in image_files:\n",
    "    \n",
    "#     image_path = os.path.join(image_folder, image_file)\n",
    "    \n",
    "#     # #slakt\n",
    "#     # crop_img_rgb = process_and_display_image(image_path, x=100, y=400, w=500, h=200)\n",
    "    \n",
    "#     # # kris\n",
    "#     # crop_img_rgb = process_and_display_image(image_path, x=0, y=400, w=1200, h=500)\n",
    "    \n",
    "#     # varb\n",
    "#     crop_img_rgb = process_and_display_image(image_path, x=900, y=100, w=400, h=1000)\n",
    "    \n",
    "#     height, width = crop_img_rgb.shape[:2]\n",
    "#     print(f\"H, W: {height},{width}\")\n",
    "    \n",
    "#     # Generate unique save path for each cropped image\n",
    "#     crop_save_path = os.path.join(crop_save_folder, image_file)\n",
    "    \n",
    "#     # Save the cropped image\n",
    "#     cv2.imwrite(crop_save_path, crop_img_rgb)\n",
    "    \n",
    "#     # res_org, detections_org = predictions(image_path)  # Detections on uncropped images\n",
    "#     res_crop,detections_crop = predictions(crop_img_rgb)  # Detections on cropped images\n",
    "    \n",
    "#     # annotated_org = box_annotate(image_path, detections_org)\n",
    "#     annotated_crop = box_annotate(crop_img_rgb, detections_crop)\n",
    "    \n",
    "#     # Define the output file path\n",
    "#     output_file_path = os.path.join(detections_save_folder, os.path.splitext(image_file)[0] + '_detections.txt')\n",
    "\n",
    "#     # Write detections to the file\n",
    "#     write_detections_to_file(detections_crop, width, height, output_file_path)\n",
    "#     print(f\"Detections for {image_file} written to {output_file_path}\")\n",
    "    \n",
    "#     # # Save cropped image detections\n",
    "#     # detections_crop_save_path = os.path.join(detections_save_folder, f\"crop_{image_file}.json\")\n",
    "#     # save_detections_to_file(detections_crop, detections_crop_save_path)\n",
    "    \n",
    "#     # Generate unique save path for each annotated image\n",
    "#     save_to_filename = os.path.join(save_folder, image_file)\n",
    "\n",
    "#     # Save the annotated image\n",
    "#     cv2.imwrite(save_to_filename, annotated_crop)\n",
    "\n",
    "#     # print(f\"{image_file} Original: {res_org},{detections_org}\")\n",
    "#     # print(f\"{image_file}Croppd: {res_crop}, {detections_crop}\")\n",
    "#     # print(f\"{image_file} file saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_coco_to_yolo(coco_json_path, output_dir, image_width, image_height):\n",
    "    \n",
    "    # Remove leading/trailing whitespaces in the file path\n",
    "    coco_json_path = coco_json_path.strip()\n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.isfile(coco_json_path):\n",
    "        raise FileNotFoundError(f\"The file {coco_json_path} does not exist.\")\n",
    "    \n",
    "    with open(coco_json_path) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for img in data['images']:\n",
    "        image_id = img['id']\n",
    "        file_name = os.path.splitext(img['file_name'])[0] + '_gt.txt'\n",
    "        annotations = [a for a in data['annotations'] if a['image_id'] == image_id]\n",
    "\n",
    "        with open(os.path.join(output_dir, file_name), 'w') as file:\n",
    "            for ann in annotations:\n",
    "                # COCO format: [x_min, y_min, width, height]\n",
    "                x_min, y_min, width, height = ann['bbox']\n",
    "\n",
    "                # Convert to YOLO format: [x_center, y_center, width, height], normalized\n",
    "                x_center = x_min + width / 2\n",
    "                y_center = y_min + height / 2\n",
    "                x_center /= image_width\n",
    "                y_center /= image_height\n",
    "                width /= image_width\n",
    "                height /= image_height\n",
    "\n",
    "                # Write to file\n",
    "                file.write(f\"{ann['category_id']} {x_center} {y_center} {width} {height}\\n\")\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# width = 308  # Replace with your image width\n",
    "# height = 1200  # Replace with your image height\n",
    "\n",
    "convert_coco_to_yolo(coco_json_path, gt_save_folder, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_yolo_format_file(file_path):\n",
    "#     with open(file_path, 'r') as file:\n",
    "#         lines = file.readlines()\n",
    "#     boxes = []\n",
    "#     for line in lines:\n",
    "#         _, x_center, y_center, width, height = map(float, line.split())\n",
    "#         boxes.append((x_center, y_center, width, height))  # Exclude class_id\n",
    "#     return boxes\n",
    "\n",
    "def get_file_paths(folder, suffix):\n",
    "    file_paths = {}\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith(suffix):\n",
    "            key = file_name.replace(suffix, '')\n",
    "            file_paths[key] = os.path.join(folder, file_name)\n",
    "    return file_paths\n",
    "\n",
    "def read_yolo_format_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    boxes = []\n",
    "    for line in lines:\n",
    "        class_id, x_center, y_center, width, height = map(float, line.split())\n",
    "        boxes.append((class_id, x_center, y_center, width, height))\n",
    "    return boxes\n",
    "\n",
    "def get_file_paths(folder, suffix):\n",
    "    file_paths = {}\n",
    "    for file_name in os.listdir(folder):\n",
    "        if file_name.endswith(suffix):\n",
    "            key = file_name.replace(suffix, '')\n",
    "            file_paths[key] = os.path.join(folder, file_name)\n",
    "    return file_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_iou(box1, box2):\n",
    "#     \"\"\"\n",
    "#     Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "    \n",
    "#     Parameters:\n",
    "#     box1 (tuple): bounding box in format (x1, y1, x2, y2).\n",
    "#     box2 (tuple): bounding box in format (x1, y1, x2, y2).\n",
    "    \n",
    "#     Returns:\n",
    "#     float: IoU value.\n",
    "#     \"\"\"\n",
    "#     # Determine the coordinates of the intersection rectangle\n",
    "#     x_left = max(box1[0], box2[0])\n",
    "#     y_top = max(box1[1], box2[1])\n",
    "#     x_right = min(box1[2], box2[2])\n",
    "#     y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "#     if x_right < x_left or y_bottom < y_top:\n",
    "#         return 0.0\n",
    "\n",
    "#     # Calculate intersection area\n",
    "#     intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "#     # Calculate union area\n",
    "#     box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "#     box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "#     union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "#     # Compute IoU\n",
    "#     iou = intersection_area / union_area\n",
    "\n",
    "#     return iou\n",
    "\n",
    "def calculate_iou(box1, box2):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Calculate the Intersection over Union (IoU) of two bounding boxes.\n",
    "\n",
    "    \n",
    "\n",
    "    Parameters:\n",
    "\n",
    "    box1 (tuple): bounding box in format (x_center, y_center, width, height), normalized coordinates.\n",
    "\n",
    "    box2 (tuple): bounding box in format (x_center, y_center, width, height), normalized coordinates.\n",
    "\n",
    "    \n",
    "\n",
    "    Returns:\n",
    "\n",
    "    float: IoU value.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert the center coordinates to x_min, y_min, x_max, y_max format\n",
    "\n",
    "    def convert(box):\n",
    "\n",
    "        x_center, y_center, width, height = box\n",
    "\n",
    "        x_min = x_center - width / 2\n",
    "\n",
    "        y_min = y_center - height / 2\n",
    "\n",
    "        x_max = x_center + width / 2\n",
    "\n",
    "        y_max = y_center + height / 2\n",
    "\n",
    "        return [x_min, y_min, x_max, y_max]\n",
    "\n",
    "\n",
    "\n",
    "    box1 = convert(box1)\n",
    "\n",
    "    box2 = convert(box2)\n",
    "\n",
    "\n",
    "\n",
    "    # Determine the coordinates of the intersection rectangle\n",
    "\n",
    "    x_left = max(box1[0], box2[0])\n",
    "\n",
    "    y_top = max(box1[1], box2[1])\n",
    "\n",
    "    x_right = min(box1[2], box2[2])\n",
    "\n",
    "    y_bottom = min(box1[3], box2[3])\n",
    "\n",
    "\n",
    "\n",
    "    if x_right < x_left or y_bottom < y_top:\n",
    "\n",
    "        return 0.0\n",
    "\n",
    "\n",
    "\n",
    "    intersection_area = (x_right - x_left) * (y_bottom - y_top)\n",
    "\n",
    "    box1_area = (box1[2] - box1[0]) * (box1[3] - box1[1])\n",
    "\n",
    "    box2_area = (box2[2] - box2[0]) * (box2[3] - box2[1])\n",
    "\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "\n",
    "\n",
    "\n",
    "    iou = intersection_area / union_area\n",
    "\n",
    "    return iou\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def calculate_iou_for_each_image(ground_truth_folder, detections_folder, image_folder):\n",
    "# #     ground_truth_files = get_file_paths(ground_truth_folder, '_gt.txt')\n",
    "# #     detection_files = get_file_paths(detections_folder, '_detections.txt')\n",
    "\n",
    "# #     for image_key in ground_truth_files:\n",
    "# #         if image_key in detection_files:\n",
    "# #             ground_truth_boxes = read_yolo_format_file(ground_truth_files[image_key])\n",
    "# #             detection_boxes = read_yolo_format_file(detection_files[image_key])\n",
    "\n",
    "# #             # Assuming single object per image for simplicity\n",
    "# #             if ground_truth_boxes and detection_boxes:\n",
    "# #                 gt_box = ground_truth_boxes[0][1:]  # Exclude class_id\n",
    "# #                 det_box = detection_boxes[0][1:]  # Exclude class_id\n",
    "# #                 iou = calculate_iou(gt_box, det_box)\n",
    "\n",
    "# #                 # Visualize\n",
    "# #                 image_path = os.path.join(image_folder, image_key + '.jpg')\n",
    "# #                 visualize_boxes_and_iou(image_path, gt_box, det_box, iou)\n",
    "\n",
    "# def calculate_iou_for_each_image(ground_truth_folder, detections_folder, image_folder):\n",
    "    \n",
    "#     ground_truth_files = get_file_paths(ground_truth_folder, '_gt.txt')\n",
    "#     detection_files = get_file_paths(detections_folder, '_detections.txt')\n",
    "\n",
    "#     for image_key in ground_truth_files:\n",
    "#         if image_key in detection_files:\n",
    "#             ground_truth_boxes = read_yolo_format_file(ground_truth_files[image_key])\n",
    "#             detection_boxes = read_yolo_format_file(detection_files[image_key])\n",
    "\n",
    "#             # Check if there are boxes in both ground truth and detection files\n",
    "#             if ground_truth_boxes and detection_boxes:\n",
    "#                 for gt_box in ground_truth_boxes:\n",
    "#                     for det_box in detection_boxes:\n",
    "#                         # Calculate IoU for each pair of ground truth and detection box\n",
    "#                         gt_box_coords = gt_box[1:]  # Exclude class_id for IoU calculation\n",
    "#                         det_box_coords = det_box[1:]  # Exclude class_id for IoU calculation\n",
    "#                         iou = calculate_iou(gt_box_coords, det_box_coords)\n",
    "\n",
    "#                         # Visualize\n",
    "#                         image_path = os.path.join(image_folder, image_key + '.jpg')\n",
    "#                         visualize_boxes_and_iou(image_path, gt_box_coords, det_box_coords, iou)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_boxes_and_iou(image_path, gt_boxes, det_boxes, ious):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    for gt_box, det_box, iou in zip(gt_boxes, det_boxes, ious):\n",
    "        # Convert normalized coordinates to pixel coordinates\n",
    "        gt_box_pixel = convert_to_pixel_coordinates(gt_box, w, h)\n",
    "        det_box_pixel = convert_to_pixel_coordinates(det_box, w, h)\n",
    "\n",
    "        # Draw boxes\n",
    "        image = cv2.rectangle(image, (gt_box_pixel[0], gt_box_pixel[1]), (gt_box_pixel[2], gt_box_pixel[3]), (0, 255, 0), 2)\n",
    "        image = cv2.rectangle(image, (det_box_pixel[0], det_box_pixel[1]), (det_box_pixel[2], det_box_pixel[3]), (255, 0, 0), 2)\n",
    "\n",
    "        # Display IoU\n",
    "        cv2.putText(image, f'IoU: {iou:.2f}', (det_box_pixel[0], det_box_pixel[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def convert_to_pixel_coordinates(box, width, height):\n",
    "    x_center, y_center, w, h = box\n",
    "    x_min = int((x_center - w / 2) * width)\n",
    "    y_min = int((y_center - h / 2) * height)\n",
    "    x_max = int((x_center + w / 2) * width)\n",
    "    y_max = int((y_center + h / 2) * height)\n",
    "    return x_min, y_min, x_max, y_max\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, gt_file, det_file):\n",
    "    gt_data = read_yolo_format_file(gt_file)\n",
    "    det_data = read_yolo_format_file(det_file)\n",
    "\n",
    "    ious = []\n",
    "    for gt in gt_data:\n",
    "        gt_box = gt[1:]  # Extract only the bounding box coordinates\n",
    "        for det in det_data:\n",
    "            det_box = det[1:]  # Extract only the bounding box coordinates\n",
    "            iou = calculate_iou(gt_box, det_box)\n",
    "            ious.append(iou)\n",
    "\n",
    "    visualize_boxes_and_iou(image_path, [box[1:] for box in gt_data], [box[1:] for box in det_data], ious)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_matching_files(image_folder, ground_truth_folder, detections_folder):\n",
    "    for filename in os.listdir(image_folder):\n",
    "        if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        base_filename = os.path.splitext(filename)[0]\n",
    "        gt_file = os.path.join(ground_truth_folder, base_filename + '_gt.txt')\n",
    "        det_file = os.path.join(detections_folder, base_filename + '_detections.txt')\n",
    "\n",
    "        if os.path.exists(gt_file) and os.path.exists(det_file):\n",
    "            image_path = os.path.join(image_folder, filename)\n",
    "            process_image(image_path, gt_file, det_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process_matching_files(crop_save_folder, gt_save_folder, detections_save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_dotted_rect(image, pt1, pt2, color, thickness=2, dot_length=3, gap_length=3):\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "\n",
    "    # Drawing horizontal dotted lines\n",
    "    for x in range(x1, x2, dot_length + gap_length):\n",
    "        cv2.line(image, (x, y1), (min(x + dot_length, x2), y1), color, thickness)\n",
    "        cv2.line(image, (x, y2), (min(x + dot_length, x2), y2), color, thickness)\n",
    "\n",
    "    # Drawing vertical dotted lines\n",
    "    for y in range(y1, y2, dot_length + gap_length):\n",
    "        cv2.line(image, (x1, y), (x1, min(y + dot_length, y2)), color, thickness)\n",
    "        cv2.line(image, (x2, y), (x2, min(y + dot_length, y2)), color, thickness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(tp, fp, fn):\n",
    "    \"\"\"\n",
    "    Calculate precision, recall, and F1-score.\n",
    "    \n",
    "    Parameters:\n",
    "    tp (int): Number of true positives\n",
    "    fp (int): Number of false positives\n",
    "    fn (int): Number of false negatives\n",
    "    \n",
    "    Returns:\n",
    "    tuple: precision, recall, F1-score\n",
    "    \"\"\"\n",
    "    precision = tp / (tp + fp) if (tp + fp) else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) else 0\n",
    "\n",
    "    return precision, recall, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_detections(image_path, gt_boxes, det_boxes, iou_threshold=0.5):\n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    legend = {\n",
    "        'Green': 'Ground Truth',\n",
    "        'Red': 'False Positive',\n",
    "        'Blue': 'True Positive',\n",
    "        # 'Orange': 'False Positive',\n",
    "        #'Yellow': 'False Negative'\n",
    "    }\n",
    "\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "\n",
    "    # Drawing ground truth boxes with dotted lines\n",
    "    for gt_box in gt_boxes:\n",
    "        class_id, *gt_box_coords = gt_box\n",
    "        gt_box_pixel = convert_to_pixel_coordinates(gt_box_coords, w, h)\n",
    "        \n",
    "        # Draw bounding box in green with dotted lines for ground truth\n",
    "        draw_dotted_rect(image, (gt_box_pixel[0], gt_box_pixel[1]), (gt_box_pixel[2], gt_box_pixel[3]), (0, 128, 0))\n",
    "\n",
    "    for det_box in det_boxes:\n",
    "        class_id, *det_box_coords = det_box\n",
    "        det_box_pixel = convert_to_pixel_coordinates(det_box_coords, w, h)\n",
    "        matched = False\n",
    "        iou_max = 0.0\n",
    "\n",
    "        for gt_box in gt_boxes:\n",
    "            gt_class_id, *gt_box_coords = gt_box\n",
    "            if class_id != gt_class_id:\n",
    "                continue  # Skip if class IDs do not match\n",
    "            iou = calculate_iou(gt_box_coords, det_box_coords)\n",
    "\n",
    "            if iou >= iou_threshold and iou > iou_max:\n",
    "                matched = True\n",
    "                iou_max = iou\n",
    "\n",
    "        if matched:\n",
    "            # True Positive: Blue box\n",
    "            image = cv2.rectangle(image, (det_box_pixel[0], det_box_pixel[1]), (det_box_pixel[2], det_box_pixel[3]), (0, 0, 255), 2)\n",
    "            tp += 1\n",
    "        else:\n",
    "            # False Positive: Red box\n",
    "            image = cv2.rectangle(image, (det_box_pixel[0], det_box_pixel[1]), (det_box_pixel[2], det_box_pixel[3]), (255, 0, 0), 2)\n",
    "            fp += 1\n",
    "\n",
    "    # False Negatives are ground truth boxes without a matching detection\n",
    "    for gt_box in gt_boxes:\n",
    "        class_id, *gt_box_coords = gt_box\n",
    "        gt_box_pixel = convert_to_pixel_coordinates(gt_box_coords, w, h)\n",
    "        \n",
    "        if not any(calculate_iou(gt_box_coords, det_box_coords) >= iou_threshold for det_box_coords in [box[1:] for box in det_boxes if box[0] == class_id]):\n",
    "            # Draw a yellow box for false negatives\n",
    "            # image = cv2.rectangle(image, (gt_box_pixel[0], gt_box_pixel[1]), (gt_box_pixel[2], gt_box_pixel[3]), (255, 255, 0), 2)\n",
    "            fn += 1\n",
    "\n",
    "    # Calculate True Negatives (TN)\n",
    "    tn = len(det_boxes) - tp - fp\n",
    "\n",
    "    precision, recall, f1_score = calculate_metrics(tp, fp, fn)\n",
    "    \n",
    "    # Create a figure with extra space on the right for the legend\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.imshow(image)\n",
    "    \n",
    "    # Draw the legend outside the image in the white space\n",
    "    legend_handles = [plt.Line2D([0], [0], color=color, label=f'{description}') for color, description in legend.items()]\n",
    "    ax.legend(handles=legend_handles, loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    # # Display TP, TN, FP, FN counts below the x-axis\n",
    "    # ax.text(0.1, -0.1, f'TP: {tp}', transform=ax.transAxes, fontsize=12, color='black')\n",
    "    # ax.text(0.3, -0.1, f'TN: {tn}', transform=ax.transAxes, fontsize=12, color='black')\n",
    "    # ax.text(0.5, -0.1, f'FP: {fp}', transform=ax.transAxes, fontsize=12, color='black')\n",
    "    # ax.text(0.7, -0.1, f'FN: {fn}', transform=ax.transAxes, fontsize=12, color='black')\n",
    "    # Display TP, TN, FP, FN counts in the bottom right corner\n",
    "    # tp_text = f'TP: {tp}'\n",
    "    # tn_text = f'TN: {tn}'\n",
    "    # fp_text = f'FP: {fp}'\n",
    "    # fn_text = f'FN: {fn}'\n",
    "    # text = f'{tp_text}\\n{tn_text}\\n{fp_text}\\n{fn_text}'\n",
    "    text = f\"Precision: {precision}\\nRecall: {recall}\\nF1_score: {f1_score}\"\n",
    "    ax.text(1.05, 0.005, text, fontsize=10, transform=ax.transAxes, verticalalignment='bottom')\n",
    "\n",
    "    \n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_yolo_format_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    boxes = []\n",
    "    for line in lines:\n",
    "        parts = line.split()\n",
    "        class_id = int(parts[0])  # Extract class_id\n",
    "        box_data = list(map(float, parts[1:]))  # Extract remaining values as (x_center, y_center, width, height)\n",
    "        boxes.append((class_id, *box_data))\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to process and visualize images from different folders\n",
    "def process_and_visualize_images(image_folder, gt_folder, detections_folder, output_folder):\n",
    "    image_files = [f for f in os.listdir(image_folder) if os.path.isfile(os.path.join(image_folder, f))]\n",
    "\n",
    "    for image_file in image_files:\n",
    "        image_path = os.path.join(image_folder, image_file)\n",
    "        gt_file = os.path.join(gt_folder, f\"{os.path.splitext(image_file)[0]}_gt.txt\")\n",
    "        det_file = os.path.join(detections_folder, f\"{os.path.splitext(image_file)[0]}_detections.txt\")\n",
    "\n",
    "        if os.path.exists(gt_file) and os.path.exists(det_file):\n",
    "            print(f\"Processing image: {image_file}\")\n",
    "            # Verify that the image is loaded correctly\n",
    "            if os.path.exists(image_path):\n",
    "                visualize_detections(image_path, \n",
    "                                     read_yolo_format_file(gt_file),\n",
    "                                     read_yolo_format_file(det_file),\n",
    "                                     iou_threshold=0.7)\n",
    "\n",
    "                # Define the output image file path\n",
    "                output_image_path = os.path.join(output_folder, f\"{os.path.splitext(image_file)[0]}_output.png\")\n",
    "                print(f\"Saving output image: {output_image_path}\")\n",
    "\n",
    "                # Save the output image\n",
    "                plt.savefig(output_image_path, bbox_inches='tight')\n",
    "                \n",
    "                # Close the current plot\n",
    "                plt.close()\n",
    "            else:\n",
    "                print(f\"Image file not found: {image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "process_and_visualize_images(save_folder,\n",
    "                             gt_save_folder, \n",
    "                             detections_save_folder,\n",
    "                             evals_save_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prkng_v2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
